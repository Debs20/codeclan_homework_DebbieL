---
title: "R Notebook"
output: html_notebook
---

```{r}
library(tidyverse)
library(outliers)
```


1. Load the code_clan_tweets.csv data. Find the number of rows, columns, and list all the variable names.

```{r}
cc_tweets <- read_csv("data/code_clan_tweets.csv")

```


```{r}
dim(cc_tweets)

names(cc_tweets)

head(cc_tweets)

view(cc_tweets)
```

2. First, we’re going to summarise the number of likes (favorite_count) CodeClan tweets have. Create a boxplot to check for outliers.

```{r}
ggplot(cc_tweets, aes(x = "favorite_count", favorite_count)) +
  geom_boxplot()

```




3. Find the total number of favourited tweets (stored in favorite_count) that CodeClan tweets have got. Don’t add a tweet’s favorite_count to the total when the tweet was quoted (see the is_quote variable).

```{r}
cc_tweets %>%
  filter(is_quote == FALSE) %>%
  summarise(total = sum(favorite_count))

```



Summarise the mean number of retweets (retweet_count), split by the type of platform that was used to tweet (source). Again, omit quoted tweets from the mean.

```{r}
summary(cc_tweets$retweet_count)

```

```{r}

cc_tweets %>%
  group_by(retweet_count) %>%
  summarise(n = n(), average = mean(retweet_count))
            

```


```{r}

retweet_data_mean <- cc_tweets %>%
  summarise(count = sum(retweet_count))
retweet_data_mean

```


```{r}
cc_tweets %>%
  filter(is_quote == FALSE) %>%
  group_by(source) %>%
  summarise(average_retweet = mean(retweet_count))

```



4. Count the total number of likes (i.e. total of favorite_count), split by media type, and arrange them from most likes to least. Assume that any tweets without a listed media type are of type “text”.

```{r}
cc_tweets %>%
  mutate(media_type2 = replace_na(media_type, "text")) %>%
  group_by(media_type2) %>%
  summarise(favorite_count_total = sum(favorite_count)) %>%
  arrange(desc(favorite_count_total))

```


5. Find the mean number of characters that a CodeClan tweet contains.


```{r}
cc_tweets %>%
  summarise(avg_tweet_length = mean(display_text_width))

```



6. The code_clan_info.csv data file contains status_url along with other info. Load this in, and join it to the code_clan_tweets tibble, so that you have a status_url for each tweet. Decide which variable to join the tibbles on.

```{r}
codeclan_info <- read_csv("data/code_clan_info.csv")

```


```{r}
codeclan_all <- left_join(cc_tweets, codeclan_info, by = "tweet_id")

```


7. From your new joined data, create a new tibble codeclan_hashtags containing only the tweet_id and hashtags in lowercase for analysis. Keep only those tweets with hashtags.

```{r}
codeclan_hashtag <- codeclan_all %>%
  select(tweet_id, hashtags) %>%
  mutate(lowcase_hashtag = str_to_lower(hashtags)) %>%
  select(-hashtags) %>%
  drop_na(lowcase_hashtag)

codeclan_hashtag

```



EXTENSIONS

Use the str_sub function to get the first 2 letters of each tweet

```{r}
hashtags_multiple <- codeclan_hashtag %>% 
  mutate(first_letters = str_sub(lowcase_hashtag, 1, 2)) %>%
  filter(str_detect(first_letters, "c\\("))

hashtags_multiple


```

question 10: Use the str_detect() function to find all cases where a tweet text mentions edinburgh, and count in how many tweets it appears

```{r}

cc_tweets %>%
  mutate(lowcase_tweets = str_to_lower(text)) %>%
  filter(str_detect(lowcase_tweets, "edinburgh")) %>%
  summarise(count = n())

```


question 11: use str_extract_all and regex to find usernames

```{r}
user_pattern <- "@[a-zA-Z0-9_]+"
tweets <- cc_tweets %>% 
  select(text)
head(str_extract_all(tweets$text, user_pattern))

```



```{r}



```

