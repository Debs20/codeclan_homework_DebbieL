---
title: "R Notebook"
output: html_notebook
---


HOMEWORK QUIZ

I want to predict how well 6 year-olds are going to do in their final school exams. Using the following variables am I likely under-fitting, fitting well or over-fitting? Postcode, gender, reading level, score in maths test, date of birth, family income.

  OVER FIT- 
  
CODECLAN SOLUTION

Over-fitting. Remember that most people are uniquely identifiable by their postcode, gender and date of birth. If we include all these variable in our model, or model will not be finding patterns, but identifying individuals.

If I have two models, one with an AIC score of 34,902 and the other with an AIC score of 33,559 which model should I use?
  
  34902

CODECLAN SOLUTION

The second one - lower AIC scores are better. Answer


I have two models, the first with: r-squared: 0.44, adjusted r-squared: 0.43. The second with: r-squared: 0.47, adjusted r-squared: 0.41. Which one should I use?

  FIRST
  
CODECLAN SOLUTION

The first. Adjusted r-squared is a better measure, and this has a higher adjusted r-squared value.

I have a model with the following errors: RMSE error on test set: 10.3, RMSE error on training data: 10.4. Do you think this model is over-fitting?

  YES
  
CODECLAN SOLUTON 

No, since the error is similar on the test and on the train, the model is unlikely to be over-fitting.

How does k-fold validation work?

  Generally, it’s better to use a test set, than it is to use a penalised measure of fit     because we are directly measuring the outcome we are interested in: does this model fit new data well. However, if you have a limited amount of data then penalised measures of fit have the advantage of being able to use all the data for training.

Luckily, there’s another technique available to you, that has all the advantages of a test data set, but uses all the data: k-fold cross validation.

When doing k-fold cross validation you pick a k. 10 is the usual normal value for k, but let’s use 5 as an example here.

So for 5-fold cross validation we split our data into 5 parts

CODECLAN SOLUTION

You split your data in k “folds”. For each fold, you fit on all the other data and test on that fold. Finally you measure average performance across all the folds.

What is a validation set? When do you need one?

  If you are carrying out a complex model building process, particularly if you are comparing several types of models, then you may want another hold out set: the validation set
  
CODECLAN SOLUTION

A set that is used neither to test or train your models. Used as a final measure of accuracy. They are particularly useful when you are tuning hyper-parameters.

Describe how backwards selection works.

  Start with the model containing all possible predictors (the so-called ‘full’ model)
  At each step, check all predictors in the model, and find the one that lowers r2 the least   when it is removed
  Remove this predictor from the model
  Keep note of the number of predictors in the model and the current model formula
  Go on to remove another predictor, or stop if all predictors in the model have been removed
  
CODECLAN SOLUTION

You start with a model that contains all the variables, then you remove variables one by one until you maximise some penalised measure of model fit.
  
Describe how best subset selection works.

  At each size of model, search all possible combinations of predictors for the best model    (i.e. the model with highest r2) of that size.

The effort of this algorithm increases exponentially with the number of predictors

CODECLAN SOLUTION

You find every possible subset of variables in your model. You pick the model which scores best on some penalised measure of model fit.

It is estimated on 5% of model projects end up being deployed. What actions can you take to maximise the likelihood of your model being deployed? 

Document from the outset, including rationale and approach, ensure the model validates on a recent data sample, check to ensure it does not contain illegal variables or proxies for these and ensure it can be physically implemented in a production system.

What metric could you use to confirm that the recent population is similar to the development population?

The score distribution

CODECLAN SOLUTION

The Population Stability Index (PSI)

How is the Population Stability Index defined? What does this mean in words?

In simple words, Population Stability Index (PSI) compares the distribution of a scoring variable (predicted probability) in scoring data set to a training data set that was used to develop the model. The idea is to check “How the current scoring is compared to the predicted probability from training data set”.

PSI=Σ((Actual %−Expected %)×ln(Actual %Expected %))

Above what PSI value might we need to start to consider rebuilding or recalibrating the model

above 0.2

CODECLAN SOLUTION

above 0.1

What are the common errors that can crop up when implementing a model?

Incorrectly coded in the target system, required variable manipulations not possible in the target system and different interpretations of missing or null values

After performance monitoring, if we find that the discrimination is still satisfactory but the accuracy has deteriorated, what is the recommended action?

Recalibrate the model

The root cause needs to be investigated before initiating any new model build project.

Why is it important to have a unique model identifier for each model?

So that we have a clear audit trail for all automated decisions.

Why is it important to document the modelling rationale and approach?

To enable oversight and challenge throughout the model development process